{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08c0a3c",
   "metadata": {},
   "source": [
    "# Determine Winning Nation: Deep Learning Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f760acf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'C:\\Users\\carly\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\.libs\\libbanded5x.65HX7FOLJUAC36SYG7MTJQTRYELCEJQH.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3b09e03cad40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRobustScaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[1;31m# noqa: F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m from .utils._tags import (\n\u001b[0;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pep440\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\_distributor_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\mlenv\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\Users\\carly\\anaconda3\\envs\\mlenv\\lib\\site-packages\\scipy\\.libs\\libbanded5x.65HX7FOLJUAC36SYG7MTJQTRYELCEJQH.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv\n",
    "df = pd.read_csv('data/nations_final.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b1db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468d0347",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOC_count = df['NOC'].value_counts()\n",
    "print(NOC_count)\n",
    "NOC_count.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c66495",
   "metadata": {},
   "outputs": [],
   "source": [
    "medals = df.groupby(['NOC', 'Team'])[['Total Medals', 'Golds', 'Silvers', 'Bronzes']].sum()\n",
    "medals = medals.sort_values(by=\"Total Medals\", ascending=False).reset_index()\n",
    "medals.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908997b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_medal_count = df['Total Medals'].sum()\n",
    "medals['% Medals Won'] = (medals[\"Total Medals\"]/total_medal_count * 100).round(3)\n",
    "top_nations = medals.sort_values(by=\"% Medals Won\", ascending=False)\n",
    "print(f\"Top 20 Medaling Nations: Percentage of All Medals Won\")\n",
    "print(f\"{round(sum(medals['% Medals Won'].head(20)),3)} %\")\n",
    "\n",
    "\n",
    "top_nations.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf21365",
   "metadata": {},
   "source": [
    "## Top 20 Nations: Count of Medal Type Won"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "x = top_nations.head(20)['NOC'].tolist()\n",
    "y1 = top_nations.head(20)['Golds'].tolist()\n",
    "y2 = top_nations.head(20)['Silvers'].tolist()\n",
    "y3 = top_nations.head(20)['Bronzes'].tolist()\n",
    "plt.bar(x, y1, color='g')\n",
    "plt.bar(x, y2, color='b')\n",
    "plt.bar(x, y3, color='r')\n",
    "plt.xlabel(\"Top 20 Nations\")\n",
    "plt.ylabel('Medal Count')\n",
    "plt.legend(['Gold', 'Silver', 'Bronze'])\n",
    "plt.title(\"Total Medals Won by Rank\")\n",
    "plt.xticks(x, visible=True, rotation=45)\n",
    "\n",
    "y_min = 30\n",
    "y_max = 1300\n",
    "plt.ylim([y_min, y_max])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ede015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worst Nations - Any nation not in top 20 with % medals won less than #20 rank and have at least won a medal historically\n",
    "worst_nations = top_nations[top_nations[\"% Medals Won\"]<1.326]\n",
    "print(f\"Next 20 Medaling Nations: Percentage of All Medals Won\")\n",
    "print(f\"{round(sum(worst_nations['% Medals Won'].head(20)),3)} %\")\n",
    "worst_nations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3122bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(worst_nations['NOC'].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05962fe",
   "metadata": {},
   "source": [
    "## Top 40 Nations : Total Medal Counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6ebf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "x_top = top_nations.head(20)['NOC'].tolist()\n",
    "y_top = top_nations.head(20)['Total Medals'].tolist()\n",
    "y_bottom = worst_nations.head(20)['Total Medals'].tolist()\n",
    "\n",
    "plt.bar(x, y_top, color='r')\n",
    "plt.bar(x, y_bottom, color='b')\n",
    "plt.xlabel('Top 20 Nations', fontsize=15)\n",
    "plt.ylabel('Total Medal Count')\n",
    "plt.title('Top 20 Nations vs Next 20 Nations : Total Medal Count')\n",
    "plt.xticks(x_top, visible=True, rotation=45)\n",
    "plt.legend(['Top 20', 'Next 20'])\n",
    "plt.savefig(\"images/top40.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c40415",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = list(top_nations['NOC'].head(20).unique())\n",
    "keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59541451",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(replace_noc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce number of unique naiton classifiers to 21 - Top 20 Medaling Nations and \"Other\"\n",
    "keep = list(top_nations['NOC'].head(20).unique())\n",
    "\n",
    "# Create a copy of the dataframe for iterable purposes\n",
    "df2 = df.copy()\n",
    "\n",
    "# Replace Nation in dataframe\n",
    "df2.loc[~df2['NOC'].isin(keep), 'NOC'] = \"Other\"\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "print(len(df2.NOC.value_counts()))\n",
    "df2.NOC.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee19f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check the dataframe\n",
    "df2.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7648178e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features for model\n",
    "drop_features = ['NOC','Team','Games', 'Year']\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "X = df2\n",
    "X = X.drop(drop_features, axis=1).values\n",
    "y = df2['NOC'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45bebb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing groups and scale data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da711772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Step (1): Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step (2): Convert encoded labels using to_categorical()\n",
    "y_train_cat = to_categorical(encoded_y_train, 21)\n",
    "y_test_cat = to_categorical(encoded_y_test, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429911ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 50\n",
    "hidden_nodes_layer2 = 25\n",
    "\n",
    "# Define the model\n",
    "nn= Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer- softmax =generalization of the logistic function to multiple dimensions.\n",
    "nn.add(Dense(units=21, activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfbd079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# Fit the model to the training data\n",
    "nn.fit(X_train_scaled, y_train_cat, epochs=100, shuffle=True, verbose=2)\n",
    "\n",
    "# Evaluate model using training data\n",
    "model_loss, model_accuracy = nn.evaluate(X_train_scaled,y_train_cat,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a97c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test_cat, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73008543",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(nn.predict(X_test_scaled), axis = -1)\n",
    "predicted_labels = label_encoder.inverse_transform(prediction)\n",
    "print(f\"Predicted Labels: {predicted_labels[:10]}\")\n",
    "print(f\"Actual Labels: {list(y_test[:10])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d4d00",
   "metadata": {},
   "source": [
    "# Only Predict Top 20 Nations - Filter out \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23485a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2[df2['NOC']!=\"Other\"]\n",
    "print(df3.shape)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077d8953",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['NOC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e27265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set features for model\n",
    "drop_features = ['NOC','Team','Games', 'Year']\n",
    "# Split our preprocessed data into our features and target arrays\n",
    "X = df3\n",
    "X = X.drop(drop_features, axis=1).values\n",
    "y = df3['NOC'].values\n",
    "print(X.shape, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc2af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing groups and scale data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Step (1): Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Step (2): Convert encoded labels using to_categorical()\n",
    "y_train_cat = to_categorical(encoded_y_train, 20)\n",
    "y_test_cat = to_categorical(encoded_y_test, 20)\n",
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 = 50\n",
    "hidden_nodes_layer2 = 25\n",
    "\n",
    "# Define the model\n",
    "nn= Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\", input_dim=number_input_features))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer- softmax =generalization of the logistic function to multiple dimensions.\n",
    "nn.add(Dense(units=20, activation=\"softmax\"))\n",
    "\n",
    "# Compile and fit the model\n",
    "nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model to the training data\n",
    "nn.fit(X_train_scaled, y_train_cat, epochs=100, shuffle=True, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test_cat, verbose=2)\n",
    "print(f\"Deep Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.argmax(nn.predict(X_test_scaled), axis = -1)\n",
    "predicted_labels = label_encoder.inverse_transform(prediction)\n",
    "print(f\"Predicted Labels: {predicted_labels[:10]}\")\n",
    "print(f\"Actual Labels: {list(y_test[:10])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
